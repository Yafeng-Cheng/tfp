{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0501 17:04:32.915627 140736512316352 deprecation_wrapper.py:76] From /anaconda3/envs/k_tfp/lib/python3.6/site-packages/tensorflow_probability/python/math/root_search.py:51: The name reduce_all is deprecated. Please use reduce_all instead.\n",
      "\n",
      "W0501 17:04:32.917217 140736512316352 deprecation_wrapper.py:76] From /anaconda3/envs/k_tfp/lib/python3.6/site-packages/tensorflow_probability/python/bijectors/masked_autoregressive.py:412: The name nn.relu is deprecated. Please use nn.relu instead.\n",
      "\n",
      "W0501 17:04:32.917937 140736512316352 deprecation_wrapper.py:76] From /anaconda3/envs/k_tfp/lib/python3.6/site-packages/tensorflow_probability/python/bijectors/masked_autoregressive.py:529: The name keras.layers.Layer is deprecated. Please use keras.layers.Layer instead.\n",
      "\n",
      "W0501 17:04:33.056066 140736512316352 deprecation_wrapper.py:76] From /anaconda3/envs/k_tfp/lib/python3.6/site-packages/tensorflow_probability/python/edward2/random_variable.py:191: The name Tensor is deprecated. Please use Tensor instead.\n",
      "\n",
      "W0501 17:04:33.057317 140736512316352 deprecation_wrapper.py:76] From /anaconda3/envs/k_tfp/lib/python3.6/site-packages/tensorflow_probability/python/edward2/random_variable.py:325: The name register_tensor_conversion_function is deprecated. Please use register_tensor_conversion_function instead.\n",
      "\n",
      "W0501 17:04:33.075139 140736512316352 deprecation_wrapper.py:76] From /anaconda3/envs/k_tfp/lib/python3.6/site-packages/tensorflow_probability/python/layers/dense_variational_v2.py:151: The name convert_to_tensor is deprecated. Please use convert_to_tensor instead.\n",
      "\n",
      "W0501 17:04:33.081650 140736512316352 deprecation_wrapper.py:76] From /anaconda3/envs/k_tfp/lib/python3.6/site-packages/tensorflow_probability/python/layers/distribution_layer.py:89: The name keras.layers.Lambda is deprecated. Please use keras.layers.Lambda instead.\n",
      "\n",
      "W0501 17:04:33.083792 140736512316352 deprecation_wrapper.py:76] From /anaconda3/envs/k_tfp/lib/python3.6/site-packages/tensorflow_probability/python/layers/distribution_layer.py:1136: The name keras.regularizers.Regularizer is deprecated. Please use keras.regularizers.Regularizer instead.\n",
      "\n",
      "W0501 17:04:33.085841 140736512316352 deprecation_wrapper.py:76] From /anaconda3/envs/k_tfp/lib/python3.6/site-packages/tensorflow_probability/python/layers/distribution_layer.py:1883: The name keras.utils.get_custom_objects is deprecated. Please use keras.utils.get_custom_objects instead.\n",
      "\n",
      "W0501 17:04:33.089824 140736512316352 deprecation_wrapper.py:76] From /anaconda3/envs/k_tfp/lib/python3.6/site-packages/tensorflow_probability/python/layers/initializers.py:27: The name keras.initializers.Initializer is deprecated. Please use keras.initializers.Initializer instead.\n",
      "\n",
      "W0501 17:04:33.118265 140736512316352 deprecation_wrapper.py:76] From /anaconda3/envs/k_tfp/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/sgld.py:34: The name keras.optimizers.Optimizer is deprecated. Please use keras.optimizers.Optimizer instead.\n",
      "\n",
      "W0501 17:04:33.122395 140736512316352 deprecation_wrapper.py:76] From /anaconda3/envs/k_tfp/lib/python3.6/site-packages/tensorflow_probability/python/positive_semidefinite_kernels/internal/util.py:89: The name custom_gradient is deprecated. Please use custom_gradient instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import warnings\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yafeng/Documents/GitHub/tfp'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(tensors):\n",
    "    \"\"\"Evaluates Tensor or EagerTensor to Numpy `ndarray`s.\n",
    "    Args:\n",
    "    tensors: Object of `Tensor` or EagerTensor`s; can be `list`, `tuple`,\n",
    "      `namedtuple` or combinations thereof.\n",
    " \n",
    "    Returns:\n",
    "      ndarrays: Object with same structure as `tensors` except with `Tensor` or\n",
    "        `EagerTensor`s replaced by Numpy `ndarray`s.\n",
    "    \"\"\"\n",
    "    if tf.executing_eagerly():\n",
    "        return tf.contrib.framework.nest.pack_sequence_as(\n",
    "            tensors,\n",
    "            [t.numpy() if tf.contrib.framework.is_tensor(t) else t\n",
    "             for t in tf.contrib.framework.nest.flatten(tensors)])\n",
    "    return sess.run(tensors)\n",
    "\n",
    "\n",
    "class _TFColor(object):\n",
    "    \"\"\"Enum of colors used in TF docs.\"\"\"\n",
    "    red = '#F15854'\n",
    "    blue = '#5DA5DA'\n",
    "    orange = '#FAA43A'\n",
    "    green = '#60BD68'\n",
    "    pink = '#F17CB0'\n",
    "    brown = '#B2912F'\n",
    "    purple = '#B276B2'\n",
    "    yellow = '#DECF3F'\n",
    "    gray = '#4D4D4D'\n",
    "    def __getitem__(self, i):\n",
    "        return [\n",
    "            self.red,\n",
    "            self.orange,\n",
    "            self.green,\n",
    "            self.blue,\n",
    "            self.pink,\n",
    "            self.brown,\n",
    "            self.purple,\n",
    "            self.yellow,\n",
    "            self.gray,\n",
    "        ][i % 9]\n",
    "TFColor = _TFColor()\n",
    "\n",
    "def session_options(enable_gpu_ram_resizing=True, enable_xla=False):\n",
    "    \"\"\"\n",
    "    Allowing the notebook to make use of GPUs if they're available.\n",
    "    \n",
    "    XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear \n",
    "    algebra that optimizes TensorFlow computations.\n",
    "    \"\"\"\n",
    "    config = tf.ConfigProto()\n",
    "    config.log_device_placement = True\n",
    "    if enable_gpu_ram_resizing:\n",
    "        # `allow_growth=True` makes it possible to connect multiple colabs to your\n",
    "        # GPU. Otherwise the colab malloc's all GPU ram.\n",
    "        config.gpu_options.allow_growth = True\n",
    "    if enable_xla:\n",
    "        # Enable on XLA. https://www.tensorflow.org/performance/xla/.\n",
    "        config.graph_options.optimizer_options.global_jit_level = (\n",
    "            tf.OptimizerOptions.ON_1)\n",
    "    return config\n",
    "\n",
    "\n",
    "def reset_sess(config=None):\n",
    "    \"\"\"\n",
    "    Convenience function to create the TF graph & session or reset them.\n",
    "    \"\"\"\n",
    "    if config is None:\n",
    "        config = session_options(enable_gpu_ram_resizing=True, enable_xla=False)\n",
    "    global sess\n",
    "    tf.reset_default_graph()\n",
    "    try:\n",
    "        sess.close()\n",
    "    except:\n",
    "        pass\n",
    "    sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'ConfigProto'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-03d8a3abeee6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreset_sess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-67393e9c1e97>\u001b[0m in \u001b[0;36mreset_sess\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menable_gpu_ram_resizing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_xla\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-67393e9c1e97>\u001b[0m in \u001b[0;36msession_options\u001b[0;34m(enable_gpu_ram_resizing, enable_xla)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0malgebra\u001b[0m \u001b[0mthat\u001b[0m \u001b[0moptimizes\u001b[0m \u001b[0mTensorFlow\u001b[0m \u001b[0mcomputations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \"\"\"\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_device_placement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0menable_gpu_ram_resizing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/k_tfp/lib/python3.6/site-packages/tensorflow/python/util/deprecation_wrapper.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dw_deprecated_printed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dw_warning_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dw_wrapped_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=super-on-old-class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'ConfigProto'"
     ]
    }
   ],
   "source": [
    "reset_sess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_data = tf.constant([\n",
    "    13,  24,   8,  24,   7,  35,  14,  11,  15,  11,  22,  22,  11,  57,  \n",
    "    11,  19,  29,   6,  19,  12,  22,  12,  18,  72,  32,   9,   7,  13,  \n",
    "    19,  23,  27,  20,   6,  17,  13,  10,  14,   6,  16,  15,   7,   2,  \n",
    "    15,  15,  19,  70,  49,   7,  53,  22,  21,  31,  19,  11,  18,  20,  \n",
    "    12,  35,  17,  23,  17,   4,   2,  31,  30,  13,  27,   0,  39,  37,   \n",
    "    5,  14,  13,  22,\n",
    "], dtype=tf.float32)\n",
    "count_data_mean = tf.reduce_mean(count_data)\n",
    "n_count_data = tf.shape(count_data)\n",
    "count_of_text_msgs = tf.range(n_count_data[0])\n",
    "\n",
    "# Convert from TF to numpy.\n",
    "\n",
    "[\n",
    "    count_data_, \n",
    "    count_data_mean_,\n",
    "    n_count_data_, \n",
    "    count_of_text_msgs_,\n",
    "] = evaluate([\n",
    "    count_data, \n",
    "    count_data_mean,\n",
    "    n_count_data,\n",
    "    count_of_text_msgs,\n",
    "])\n",
    "\n",
    "# Visualizing the Results\n",
    "    \n",
    "plt.figure(figsize=(12.5, 4))\n",
    "plt.bar(count_of_text_msgs_, count_data_, color=\"#5DA5DA\")\n",
    "plt.xlabel(\"Time (days)\")\n",
    "plt.ylabel(\"count of text-msgs received\")\n",
    "plt.title(\"Did the user's texting habits change over time?\")\n",
    "plt.xlim(0, n_count_data_[0]);\n",
    "\n",
    "print(\"Count Data Mean: \", count_data_mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(count_data_, bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the chain's start state.\n",
    "initial_chain_state = [\n",
    "    tf.to_float(tf.reduce_mean(count_data)) * tf.ones([], dtype=tf.float32, name=\"init_lambda1\"),\n",
    "    tf.to_float(tf.reduce_mean(count_data)) * tf.ones([], dtype=tf.float32, name=\"init_lambda2\"),\n",
    "    0.5 * tf.ones([], dtype=tf.float32, name=\"init_tau\"),\n",
    "]\n",
    "\n",
    "\n",
    "# Since HMC operates over unconstrained space, we need to transform the\n",
    "# samples so they live in real-space.\n",
    "unconstraining_bijectors = [\n",
    "    tfp.bijectors.Exp(),       # Maps a positive real to R.\n",
    "    tfp.bijectors.Exp(),       # Maps a positive real to R.\n",
    "    tfp.bijectors.Sigmoid(),   # Maps [0,1] to R.  \n",
    "]\n",
    "\n",
    "\n",
    "def joint_log_prob(count_data, lambda_1, lambda_2, tau):\n",
    "    tfd = tfp.distributions\n",
    " \n",
    "    alpha = (1. / tf.reduce_mean(count_data))\n",
    "    rv_lambda_1 = tfd.Exponential(rate=alpha)\n",
    "    rv_lambda_2 = tfd.Exponential(rate=alpha)\n",
    " \n",
    "    rv_tau = tfd.Uniform()\n",
    " \n",
    "\n",
    "    lambda_ = tf.gather(\n",
    "         [lambda_1, lambda_2],\n",
    "         indices=tf.to_int32(tau * tf.to_float(\n",
    "             tf.size(count_data)\n",
    "         ) <= tf.to_float(\n",
    "             tf.range(tf.size(count_data))\n",
    "         )))\n",
    "    rv_observation = tfd.Poisson(rate=lambda_)\n",
    " \n",
    "    return (\n",
    "         rv_lambda_1.log_prob(lambda_1)\n",
    "         + rv_lambda_2.log_prob(lambda_2)\n",
    "         + rv_tau.log_prob(tau)\n",
    "         + tf.reduce_sum(rv_observation.log_prob(count_data))\n",
    "    )\n",
    "\n",
    "\n",
    "# Define a closure over our joint_log_prob.\n",
    "def unnormalized_log_posterior(lambda1, lambda2, tau):\n",
    "    return joint_log_prob(count_data, lambda1, lambda2, tau)\n",
    "\n",
    "\n",
    "# Initialize the step_size. (It will be automatically adapted.)\n",
    "with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE):\n",
    "    step_size = tf.get_variable(\n",
    "        name='step_size',\n",
    "        initializer=tf.constant(0.05, dtype=tf.float32),\n",
    "        trainable=False,\n",
    "        use_resource=True\n",
    "    )\n",
    "\n",
    "# Sample from the chain.\n",
    "[\n",
    "    lambda_1_samples,\n",
    "    lambda_2_samples,\n",
    "    posterior_tau,\n",
    "], kernel_results = tfp.mcmc.sample_chain(\n",
    "    num_results=100000,\n",
    "    num_burnin_steps=10000,\n",
    "    current_state=initial_chain_state,\n",
    "    kernel=tfp.mcmc.TransformedTransitionKernel(\n",
    "        inner_kernel=tfp.mcmc.HamiltonianMonteCarlo(\n",
    "            target_log_prob_fn=unnormalized_log_posterior,\n",
    "            num_leapfrog_steps=2,\n",
    "            step_size=step_size,\n",
    "            step_size_update_fn=tfp.mcmc.make_simple_step_size_update_policy(),\n",
    "            state_gradients_are_stopped=True),\n",
    "        bijector=unconstraining_bijectors))\n",
    "\n",
    "tau_samples = tf.floor(posterior_tau * tf.to_float(tf.size(count_data)))\n",
    "\n",
    "# tau_samples, lambda_1_samples, lambda_2_samples contain\n",
    "# N samples from the corresponding posterior distribution\n",
    "N = tf.shape(tau_samples)[0]\n",
    "expected_texts_per_day = tf.zeros(n_count_data)\n",
    "\n",
    "\n",
    "# Initialize any created variables.\n",
    "init_g = tf.global_variables_initializer()\n",
    "init_l = tf.local_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(init_g)\n",
    "evaluate(init_l)\n",
    "[\n",
    "    lambda_1_samples_,\n",
    "    lambda_2_samples_,\n",
    "    tau_samples_,\n",
    "    kernel_results_,\n",
    "    N_,\n",
    "    expected_texts_per_day_,\n",
    "] = evaluate([\n",
    "    lambda_1_samples,\n",
    "    lambda_2_samples,\n",
    "    tau_samples,\n",
    "    kernel_results,\n",
    "    N,\n",
    "    expected_texts_per_day,\n",
    "])\n",
    "\n",
    "    \n",
    "print(\"acceptance rate: {}\".format(\n",
    "    kernel_results_.inner_results.is_accepted.mean()))\n",
    "print(\"final step size: {}\".format(\n",
    "    kernel_results_.inner_results.extra.step_size_assign[-100:].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12.5, 15))\n",
    "#histogram of the samples:\n",
    "\n",
    "ax = plt.subplot(311)\n",
    "ax.set_autoscaley_on(False)\n",
    "\n",
    "plt.hist(lambda_1_samples_, histtype='stepfilled', bins=30, alpha=0.85,\n",
    "         label=r\"posterior of $\\lambda_1$\", color=TFColor[0], normed=True)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title(r\"\"\"Posterior distributions of the variables $\\lambda_1,\\;\\lambda_2,\\;\\tau$\"\"\")\n",
    "plt.xlim([15, 30])\n",
    "plt.xlabel(r\"$\\lambda_1$ value\")\n",
    "\n",
    "ax = plt.subplot(312)\n",
    "ax.set_autoscaley_on(False)\n",
    "plt.hist(lambda_2_samples_, histtype='stepfilled', bins=30, alpha=0.85,\n",
    "         label=r\"posterior of $\\lambda_2$\", color=TFColor[6], normed=True)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlim([15, 30])\n",
    "plt.xlabel(r\"$\\lambda_2$ value\")\n",
    "\n",
    "plt.subplot(313)\n",
    "w = 1.0 / tau_samples_.shape[0] * np.ones_like(tau_samples_)\n",
    "plt.hist(tau_samples_, bins=n_count_data_[0], alpha=1,\n",
    "         label=r\"posterior of $\\tau$\",\n",
    "         color=TFColor[2], weights=w, rwidth=2.)\n",
    "plt.xticks(np.arange(n_count_data_[0]))\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.ylim([0, .75])\n",
    "plt.xlim([35, len(count_data_)-20])\n",
    "plt.xlabel(r\"$\\tau$ (in days)\")\n",
    "plt.ylabel(r\"probability\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfp2",
   "language": "python",
   "name": "k_tfp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
